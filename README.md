# ML Credit Risk Analysis

> Predicci√≥n de riesgo crediticio con pipelines reproducibles, importancia de variables y flujo de scoring/visualizaci√≥n. Incluye API/Frontend opcional para demo.

## üì¶ Componentes principales

Este proyecto sigue una arquitectura modular inspirada en buenas pr√°cticas de MLOps, separando claramente:

- pipelines de entrenamiento,
- l√≥gica de preprocesamiento,
- API de inferencia,
- frontend de demo,
- artefactos del modelo,
- notebooks exploratorios.

A continuaci√≥n se detallan los componentes clave del repositorio.

---

### üß† `src/` ‚Äî L√≥gica principal del proyecto

#### üîπ `src/features/`
- `build_features.py`  
  Implementa el pipeline de preprocesamiento completo:
  - `BaseCleaner` (limpieza + feature engineering)
  - `CodeImputerWithFlag` (imputaci√≥n robusta de c√≥digos)
  - `build_preprocessing_pipeline()` (ColumnTransformer final)

#### üîπ `src/pipelines/`
Incluye los **pipelines reproducibles de entrenamiento**:

- `data_preparation_pipeline.py`  
  Limpieza inicial y generaci√≥n de datasets en `data/interim/` y `data/processed/`.

- `train_preprocessing.py`  
  Entrena el preprocesador completo y guarda el artefacto:  
  `model_service/artifacts/preprocessing_pipeline.joblib`

- `train_model_stack.py`  
  Entrena el modelo de stacking (XGBoost + LightGBM + meta-XGB)  
  y genera:  
  - `model_stack_prod.pkl`  
  - `model_metadata.json`

#### üîπ `src/utils/`
- `split.py`  
  Funciones auxiliares para dividir dataset en train/test.

---

### ü§ñ `model_service/` ‚Äî Servicio de inferencia (API + worker)

Contiene todo lo necesario para correr el modelo en producci√≥n dentro de Docker.

#### üîπ `model_service/app/`
- `main.py`  
  Servicio FastAPI principal: carga modelo + preprocesador.
- `worker.py`  
  Worker RQ para tareas en background (inferencias asincr√≥nicas).

##### `model_service/app/model/`
- `pipeline.py`  
  Inicializaci√≥n del modelo y preprocesador.
- `preprocess.py`  
  Utilidades para aplicar transformaciones y validaciones en inferencia.

##### `model_service/app/utils/`
- `schema.py`  
  Esquemas Pydantic para requests (`PredictionRequest`, batch, etc.)
- `utils.py`  
  Funciones auxiliares del servicio.

#### üîπ `model_service/artifacts/`
Contiene los artefactos entrenados:

- `preprocessing_pipeline.joblib`
- `model_stack_prod.pkl`
- `model_metadata.json`

---

### üß© `api/` ‚Äî API completa con autenticaci√≥n (opcional)

Una API alternativa, con estructura cl√°sica de FastAPI:

- `app/main.py` ‚Äî punto de entrada
- `auth/` ‚Äî login, JWT, dependencias, validadores
- `users/` ‚Äî modelos y repositorio de usuarios
- `predictions/` ‚Äî endpoints de scoring

> Esta API no es necesaria para el scoring del modelo,  
> pero se mantiene como m√≥dulo separado para demo con autenticaci√≥n.

---

### üé® `frontend/` ‚Äî Aplicaci√≥n Streamlit para demo

- `streamlit_app.py` ‚Äî interfaz principal
- `credit_form_interface.py` ‚Äî mapeo de campos ‚Üí payload para modelo
- `field_options.json` ‚Äî cat√°logos (sex, estados, productos, etc.)
- `utils.py` ‚Äî funciones del frontend

El frontend permite:
- cargar datos manualmente
- obtener un scoring del modelo
- visualizar m√©tricas y simulaciones simples

---

### üìä `notebooks/` ‚Äî Exploraci√≥n y prototipos

- `01_EDA.ipynb` ‚Äî an√°lisis exploratorio
- `03_Model_Visualization.ipynb` ‚Äî an√°lisis exploratorio

> El entrenamiento final NO depende del notebook,  
> sino de los scripts en `src/pipelines/`.

---

### üìÅ `data/` ‚Äî Dataset estructurado por etapas

- `raw/` ‚Äî datos originales  
- `interim/` ‚Äî datos intermedios limpios  
- `processed/` ‚Äî datasets finales para entrenamiento (X_train, y_train, etc.)

M√°s detalle en la secci√≥n **üóÇÔ∏è Datos**.


## üß∞ Requisitos y entorno

- Python 3.10 recomendado (Windows soportado)
- Instalar dependencias:

```powershell
python -m venv venv
venv\Scripts\Activate.ps1
pip install -r requirements.txt
pip install -e .
```

Notas:
- Para leer el archivo .XLS del dataset se fija xlrd==1.2.0 (las versiones ‚â•2.0 ya no soportan .xls).
- LightGBM y CatBoost est√°n incluidos en requirements y se usan si est√°n instalados.

## üóÇÔ∏è Datos

El proyecto utiliza una estructura clara para la gesti√≥n del dataset **PAKDD 2010**, separando datos **raw**, **interim** y **processed** para mantener un flujo limpio, ordenado y reproducible.

---

### üìÅ Ubicaci√≥n principal

Los datos se encuentran dentro de la carpeta:

---

### üìå `data/raw/` ‚Äî Datos originales (sin modificar)

Archivos requeridos:

- `PAKDD2010_VariablesList.XLS` ‚Äî Diccionario de variables (nombres y descripciones)
- `PAKDD2010_Modeling_Data.txt` ‚Äî Dataset para entrenamiento
- `PAKDD2010_Prediction_Data.txt` ‚Äî Dataset para scoring/predicci√≥n

Archivo adicional utilizado por el frontend:

- `cities.csv` ‚Äî Cat√°logo opcional para autocompletado de ciudades

---

### üìÅ `data/interim/` ‚Äî Datos intermedios

Archivos generados durante la etapa de limpieza inicial:

- `train_clean_headers.parquet` ‚Äî Versi√≥n del dataset con encabezados corregidos y estructura estandarizada

---

### üìÅ `data/processed/` ‚Äî Datos finales para modelado

Archivos generados autom√°ticamente por los pipelines de preprocesamiento:

- `X_train.parquet`
- `X_test.parquet`
- `y_train.parquet`
- `y_test.parquet`

Estos archivos representan los datasets listos para entrenamiento y evaluaci√≥n de modelos.


## üß™ Uso del notebook principal

1) Abrir `notebooks/02_Feature_Engineering_Modelado.ipynb` y ejecutar en orden:
     - Celda 1: carga de datos.
     - Celda 2: agrupaci√≥n de variables, exclusiones y DataFrame FINAL (auditable).
     - Celda 3: construcci√≥n del preprocesador y resumen de columnas generadas.
     - Celda 4: importancia con XGBoost; umbral configurable; crea `preprocessor_filtered` con variables ‚â• umbral (por defecto 0.02 en el cuaderno; se puede ajustar).
     - Celda 5: entrenamiento y evaluaci√≥n de modelos activos (RF, XGBoost, LightGBM, CatBoost).
     - Celda 6: predicciones sobre `Prediction_Data.txt` y columnas `score_*` en `df_pred`.
     - Celda 7: histogramas de scores por modelo.

2) B√∫squeda de hiperpar√°metros (RandomizedSearchCV):
     - La celda de HPO incluye un flag `HPO_ENABLED = False` para evitar ejecuciones largas. Cambiar a `True` para activar.
     - Los mejores pipelines quedan en `tuned_models`.
     - En la celda de predicciones, `USE_TUNED_MODELS = False` por defecto. Cambiar a `True` para usar `tuned_models` si existen.

## üîß Pipelines de Entrenamiento (MLOps)

Adem√°s del flujo interactivo en notebooks, este proyecto incluye pipelines reproducibles en src/pipelines/ que permiten entrenar el modelo de manera estandarizada, sin depender del notebook.

Estos scripts orquestan el flujo completo:

1. Preparaci√≥n de Datos

python src/pipelines/data_preparation_pipeline.py

Limpia y organiza los datos raw, generando los datasets listos para preprocesamiento.

2. Entrenamiento del Preprocesador

python src/pipelines/train_preprocessing.py

Entrena el ColumnTransformer final y guarda el artefacto:
model_service/artifacts/preprocessing_pipeline.joblib

3. Entrenamiento del Modelo (Stacking)

python src/pipelines/train_model_stack.py

Entrena el modelo de producci√≥n y genera:

model_service/artifacts/model_stack_prod.pkl
model_service/artifacts/model_metadata.json

Estos artefactos son cargados autom√°ticamente por el servicio FastAPI al iniciar, permitiendo usar el modelo entrenado sin depender del notebook.

## ü§ñ Modelos incluidos

- Random Forest (scikit-learn)
- XGBoost (xgboost)
- LightGBM (lightgbm) ‚Äì opcional si instalado
- CatBoost (catboost) ‚Äì opcional si instalado
- (Opcional) GB leaves ‚Üí OneHot ‚Üí LR (√∫til para calibraci√≥n y capturar interacciones de √°rboles)

## üß© Dise√±o del preprocesamiento


El proyecto utiliza un pipeline de preprocesamiento **100% reproducible y compatible con scikit-learn**, construido mediante:

- **`BaseCleaner`** ‚Üí limpieza avanzada + feature engineering
- **`CodeImputerWithFlag`** ‚Üí imputaci√≥n robusta para c√≥digos num√©ricos con flags
- **`ColumnTransformer`** ‚Üí preprocesamiento paralelo por tipo de variable
- **`build_preprocessing_pipeline()`** ‚Üí ensamblado final listo para entrenamiento e inferencia

---

### üîπ 1. Limpieza y Feature Engineering ‚Äî `BaseCleaner`

`BaseCleaner` aplica transformaciones consistentes sobre los datos raw:

- Conversi√≥n de errores de Excel (`#N/A`, `#DIV/0!`, etc.) a `NaN`
- Normalizaci√≥n de estados, c√≥digos y columnas categ√≥ricas problem√°ticas
- Generaci√≥n de nuevas features:
  - `N_CARDS` (conteo total de tarjetas)
  - `TOTAL_INCOME`, `INCOME_PER_DEPENDANT`, `LOG_TOTAL_INCOME`
  - `HAS_CARDS`
  - `WORKS_SAME_STATE`
  - Binning de edad ‚Üí `AGE_GROUP`
- Correcci√≥n de outliers espec√≠ficos (`QUANT_DEPENDANTS > 15`)
- Dropeo de columnas ruidosas/irrelevantes (IDs, boroughs, flags redundantes, etc.)
- Conversi√≥n de Y/N ‚Üí 1/0 en variables binarias

> Este paso concentra toda la ingenier√≠a de features previa al ColumnTransformer.

---

### üîπ 2. Imputaci√≥n especializada de c√≥digos ‚Äî `CodeImputerWithFlag`

Las columnas de c√≥digos num√©ricos reciben un tratamiento especial:

- Imputaci√≥n con un valor fijo (`-1`)
- Creaci√≥n autom√°tica de un flag `<col>_WAS_NULL`
- Salida 100% num√©rica y consistente
- Compatible con scikit-learn y modelado basado en √°rboles

Beneficios:
- Preserva informaci√≥n sobre valores faltantes  
- Mantiene compatibilidad con modelos tree-based  
- Mejora estabilidad e interpretabilidad  

---

### üîπ 3. ColumnTransformer ‚Äî Preprocesamiento unificado

Las columnas se agrupan en tres bloques:

#### **‚û§ NUMERIC_FEATS**
- Imputaci√≥n: mediana  
- Escalado: `StandardScaler`

#### **‚û§ OHE_FEATS**
- Imputaci√≥n: moda  
- Codificaci√≥n: `OneHotEncoder(handle_unknown='ignore')`

#### **‚û§ CODE_FEATS**
- Imputaci√≥n + flags: `CodeImputerWithFlag`

El resultado es un preprocesamiento robusto, interpretable y listo para producci√≥n.

---

### üîπ 4. Pipeline final

El pipeline completo se arma as√≠:

BaseCleaner
‚Üì
ColumnTransformer
(numeric_pipe + categorical_pipe + code_pipe)
‚Üì
Dataset final listo para modelado

Este pipeline se serializa como artefacto para inferencia:

- `model_service/artifacts/preprocessing_pipeline.joblib`

---

### üß† Resumen

A diferencia del preprocesamiento tradicional (winsor, target encoding, cuantiles), este proyecto implementa un pipeline propio:

- Limpieza manual detallada  
- Feature engineering guiado por l√≥gica de negocio  
- ColumnTransformer transparente  
- Imputaci√≥n con flags para c√≥digos num√©ricos  
- Total compatibilidad con scikit-learn y MLOps

El resultado es un preprocesamiento **robusto, reproducible y listo para producci√≥n**.

## üìä M√©tricas e informaci√≥n del modelo (model_metadata.json)

Durante el entrenamiento del modelo stacking, el proyecto genera un archivo:

- `model_service/artifacts/model_metadata.json`


Este archivo contiene **m√©tricas clave del modelo final**, calculadas sobre el set de test:

- **AUC (`auc`)**  
  Medida general de discriminaci√≥n del modelo.

- **Mejor umbral (`best_threshold`)**  
  Obtenido maximizando el F1-score mediante la curva Precision-Recall.

- **F1-score √≥ptimo (`best_f1`)**

- **Flag de calibraci√≥n (`calibrated`)**  
  Indica si el modelo final usa calibraci√≥n de probabilidades v√≠a Isotonic Regression.

Ejemplo real generado por el pipeline:

```json
{
    "auc": 0.6476,
    "best_threshold": 0.2466,
    "best_f1": 0.4550,
    "calibrated": true
}

Nota:
A diferencia de otros enfoques, este proyecto no aplica filtrado de variables por importancia.
El archivo model_metadata.json se utiliza para auditor√≠a del modelo, selecci√≥n del umbral √≥ptimo y trazabilidad del entrenamiento.

## ‚ñ∂Ô∏è API / Frontend (opcional)

Para demo r√°pida (cuando quieras mostrar un servicio):

```powershell
uvicorn api.main:app --reload --port 8000
# Docs: http://localhost:8000/docs

streamlit run frontend/streamlit_app.py --server.port 8501
# App: http://localhost:8501
```

Autenticaci√≥n (demo):
- Usuarios v√°lidos: `admin/admin123` y `analyst/analyst456`.
- Si `USE_BACKEND=false`, el login se valida localmente en el frontend (modo simulado).
- Si `USE_BACKEND=true`, el frontend llama a `POST /login` en la API y guarda un `access_token` de sesi√≥n (sin autorizaci√≥n estricta para esta demo).

Esquema de entrada del modelo (`POST /predict`):
- Campos requeridos del JSON:
    - `income` (float)
    - `age` (int)
    - `credit_amount` (float)
    - `employment_length` (int, en a√±os)
    - `debt_ratio` (float, 0‚Äì1)

La UI de Streamlit mapea autom√°ticamente el formulario de ‚ÄúCredit Application Form (Manual Input)‚Äù a estos 5 campos:
- `income` = `PERSONAL_MONTHLY_INCOME` + `OTHER_INCOMES`
- `age` = `AGE`
- `employment_length` = floor(`MONTHS_IN_THE_JOB` / 12)
- `credit_amount` ‚âà 20% de `PERSONAL_ASSETS_VALUE` (si falta, usa 10000)
- `debt_ratio` ‚âà `credit_amount` / (`income`*12 + `PERSONAL_ASSETS_VALUE`) recortado a [0, 0.9]

## üê≥ Ejecutar con Docker Compose

Requisitos: Docker Desktop y Docker Compose.

1) Construir y levantar servicios (API + Frontend):
```powershell
docker compose up --build
```

2) URLs:
- Frontend: http://localhost:8501
- FastAPI: http://localhost:8000
- Docs API: http://localhost:8000/docs

Notas:
- El frontend se conecta a la API v√≠a `API_BASE_URL` (definido en docker-compose como `http://api:8000`).
- Los vol√∫menes montan `./models` y `./data` dentro de los contenedores (`/app/models`, `/app/data`).
- Healthchecks validan que cada servicio est√© listo antes de exponerlo.

Archivos de datos auxiliares (opcional):
- La UI puede cargar un cat√°logo de ciudades de Brasil desde `data/raw/cities.csv`. Rutas soportadas autom√°ticamente:
    - `./data/raw/cities.csv` (host)
    - `/app/data/raw/cities.csv` (contenedor)
    - o define `CITIES_CSV_PATH` con la ruta al CSV
- Si el archivo no existe, la UI hace fallback: Estados por sigla fija y ciudades como texto libre (no falla).

### Variables de entorno √∫tiles
- API (servicio `api`):
    - `MODEL_PATH`: ruta al artefacto del modelo o pipeline (por ejemplo, `/app/models/pipeline.joblib`).
    - `PREPROCESSOR_PATH`: ruta al preprocesador si el modelo no lo incluye.
    - `API_HOST`, `API_PORT`, `API_DEBUG` (ya preconfigurados para Docker).
- Frontend (servicio `frontend`):
    - `API_BASE_URL`: URL de la API dentro de la red de Docker (`http://api:8000`).
    - `USE_BACKEND`: `true` para consultar la API real.
    - `CITIES_CSV_PATH`: ruta al CSV de ciudades (opcional; si no existe, hay fallback seguro).

Puedes a√±adir estas variables bajo `environment:` en `docker-compose.yml` o usar un archivo `.env`.

### Endpoints principales de la API
- `POST /login` ‚Üí autenticaci√≥n demo (devuelve `access_token` si usuario/clave v√°lidos).
- `POST /predict` ‚Üí scoring individual con el esquema de 5 campos indicado arriba.
- `POST /predict/batch` ‚Üí scoring por lote (`{"profiles": [ ... ]}`).
- `POST /simulate` ‚Üí simulaci√≥n de decisiones; par√°metros:
    - `profiles`: lista de perfiles con al menos `credit_amount` si quieres m√©tricas monetarias
    - `decision_threshold` (float, default 0.5): aprueba cuando `risk_score <= threshold`
    - `profit_margin` (float, default 0.05)
- `GET /model/info` y `GET /health` ‚Üí info b√°sica y healthcheck.

### Cambiar al modelo real
1. Copia tu artefacto entrenado a `./models` (por ejemplo `./models/pipeline_real.joblib`).
2. Edita `docker-compose.yml` ‚Üí `MODEL_PATH=/app/models/pipeline_real.joblib` (y opcional `PREPROCESSOR_PATH` si usas artefactos separados).
3. Reconstruye y levanta:
     ```powershell
     docker compose up -d --build
     ```
4. Valida `/health`, `/model/info` y una predicci√≥n simple.

## üõ†Ô∏è Troubleshooting (soluci√≥n de problemas)

Estos son los errores m√°s comunes y c√≥mo resolverlos r√°pidamente.

1) Error 422 Unprocessable Entity en `/predict`
- S√≠ntomas: la app muestra ‚ÄúAPI Error: 422 ‚Ä¶‚Äù o el detalle pide campos faltantes.
- Causa: el payload no cumple el esquema del endpoint (faltan campos o nombres distintos).
- Soluci√≥n: aseg√∫rate de enviar exactamente estos 5 campos: `income` (float), `age` (int), `credit_amount` (float), `employment_length` (int), `debt_ratio` (float). La UI ya lo mapea autom√°ticamente; si pruebas con herramientas externas, respeta el esquema.

2) FileNotFoundError con `cities.csv`
- S√≠ntomas: traza en `frontend/credit_form_interface.py` al leer `cities.csv`.
- Causa: archivo ausente o ruta local no v√°lida en el contenedor.
- Soluci√≥n: coloca el archivo en `data/raw/cities.csv` (se monta en `/app/data/raw/cities.csv`) o define `CITIES_CSV_PATH`. Si no existe el archivo, la UI hace fallback a siglas de estados y ciudades como texto (no se rompe).

3) ‚ÄúInvalid credentials‚Äù al hacer login
- S√≠ntomas: el login falla siempre.
- Causas: (a) `USE_BACKEND=true` pero el endpoint `/login` no est√° en la imagen en ejecuci√≥n (falta rebuild); (b) credenciales distintas a las de demo; (c) API no alcanzable.
- Soluci√≥n: rebuild de API/Frontend, usar usuarios de demo `admin/admin123` o `analyst/analyst456`, verificar `/openapi.json` incluye `/login` y que `API_BASE_URL` apunte a la API (en Compose: `http://api:8000`).

4) Modelo no cargado / `/model/info` falla
- S√≠ntomas: `/health` indica `model_loaded: false` o el endpoint de predicci√≥n falla.
- Causa: `MODEL_PATH` o `PREPROCESSOR_PATH` apuntan a rutas inexistentes.
- Soluci√≥n: copia el artefacto real a `./models`, actualiza `MODEL_PATH` en `docker-compose.yml` (por ejemplo, `/app/models/pipeline_real.joblib`) y reconstruye.

5) Simulaci√≥n con `approved_applications=0` o ROI negativa
- Causa: con el pipeline ‚Äúdummy‚Äù los `risk_score` ‚âà 0.5; si el umbral es muy estricto, no hay aprobados; adem√°s con `profit_margin` 0.05 y `risk_score` 0.5, la p√©rdida esperada puede superar la ganancia.
- Soluci√≥n: ajusta el slider `decision_threshold` (la regla es `score <= threshold`) y/o `profit_margin`, o usa tu modelo real para scores m√°s informativos.

6) El Frontend no conecta con la API
- S√≠ntomas: ‚ÄúAPI Error ‚Ä¶ conexi√≥n‚Äù o m√©tricas que no cargan.
- Causa: `API_BASE_URL` incorrecto. Dentro de Docker Compose debe ser `http://api:8000`; en local, `http://localhost:8000`.
- Soluci√≥n: verifica variables de entorno y reconstruye si cambiaste el compose.

7) Puertos en uso (8000/8501)
- S√≠ntomas: Docker no puede publicar puertos.
- Soluci√≥n: cierra procesos que usan esos puertos o cambia el mapeo en `docker-compose.yml`.

8) Contenedores ‚Äúunhealthy‚Äù
- Causa: healthcheck falla por API ca√≠da o Frontend sin levantar.
- Soluci√≥n: revisa logs (`docker compose logs -f api` / `frontend`), valida rutas de modelo/datos, reintenta el build.

9) Batch `/predict/batch` devuelve error
- Causa: formato incorrecto.
- Soluci√≥n: env√≠a `{ "profiles": [ { five fields }, ... ] }` con el mismo esquema de `/predict` por perfil.

10) Lectura de `.xls` falla en el notebook
- Causa: `xlrd>=2.0` no soporta `.xls`.
- Soluci√≥n: usa `xlrd==1.2.0` (ya est√° en `requirements.txt`).

## ‚úÖ Checklist de reproducibilidad

- [x] requirements.txt actualizado (incluye xlrd==1.2.0, sklearn, xgboost, lightgbm, catboost, scipy, etc.)
- [x] Paquete `ml_creditrisk` con docstrings y funciones reutilizables
- [x] Notebook principal orquestando el flujo E2E
- [x] Flags para activar/desactivar HPO y usar modelos tuneados

## üìÑ Licencia

MIT (ver archivo LICENSE).
